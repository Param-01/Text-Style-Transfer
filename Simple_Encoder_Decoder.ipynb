{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2134,
     "status": "ok",
     "timestamp": 1625836742537,
     "user": {
      "displayName": "Shubham Patil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiL3C1XXiVqxpUBamrWhSAqradgI0J23eGC838ulEc=s64",
      "userId": "09238778057162358648"
     },
     "user_tz": -330
    },
    "id": "zj9V_Yg-5muT"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import re\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "title_font = {'family': 'serif', 'color': 'darkred', 'weight': 'bold', 'size': 18}\n",
    "label_font = {'family': 'Arial', 'weight': 'normal', 'size': 16}\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I-mWIzB85muU"
   },
   "source": [
    "<h2>Simple Encoder Decoder Network:</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "axp2jFCO5mua"
   },
   "source": [
    "<h3>Designing Encoder:</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 748,
     "status": "ok",
     "timestamp": 1625836839053,
     "user": {
      "displayName": "Shubham Patil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiL3C1XXiVqxpUBamrWhSAqradgI0J23eGC838ulEc=s64",
      "userId": "09238778057162358648"
     },
     "user_tz": -330
    },
    "id": "msFmaZer5mug"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    \n",
    "    \n",
    "    def __init__(self, inp_vocab_size, lstm_size, input_length):\n",
    "        \n",
    "        super().__init__()\n",
    "        # Initializing the parameters\n",
    "        self.inp_vocab_size = inp_vocab_size\n",
    "        self.lstm_size = lstm_size\n",
    "        self.input_length = input_length\n",
    "        \n",
    "        # Initializing Embedding layer\n",
    "        self.embedding = Embedding(input_dim = self.inp_vocab_size, output_dim = self.inp_vocab_size,\n",
    "                                   embeddings_initializer = tf.keras.initializers.RandomNormal(mean = 0, stddev = 1, seed = 859),\n",
    "                                   input_length = self.input_length, mask_zero = True, name = \"Encoder_Embedding\")\n",
    "        \n",
    "        #Intializing Encoder LSTM layer\n",
    "        self.lstm1 = LSTM(self.lstm_size, return_state = True, return_sequences = True,\n",
    "                          kernel_initializer = tf.keras.initializers.glorot_uniform(seed = 859),\n",
    "                          recurrent_initializer = tf.keras.initializers.orthogonal(seed = 859), name = \"Encoder_LSTM1\")\n",
    "        self.lstm2 = LSTM(self.lstm_size, return_state = True, return_sequences = True,\n",
    "                          kernel_initializer = tf.keras.initializers.glorot_uniform(seed = 859),\n",
    "                          recurrent_initializer = tf.keras.initializers.orthogonal(seed = 859), name = \"Encoder_LSTM2\")\n",
    "\n",
    "    def call(self, input):\n",
    "        \n",
    "        # Unpacking the input\n",
    "        input_sequence, states = input[0], input[1]\n",
    "        \n",
    "        # Passing input sequence to embedding layer\n",
    "        input_embedded = self.embedding(input_sequence)\n",
    "        \n",
    "        # Passing embedidng layer output to lstm layer\n",
    "        self.enc_output, self.last_hidden_state, self.last_current_state = self.lstm1(input_embedded, initial_state = states)\n",
    "        self.enc_output, self.last_hidden_state, self.last_current_state = self.lstm2(self.enc_output, [self.last_hidden_state, self.last_current_state])\n",
    "        \n",
    "        # Returning the outputs\n",
    "        return self.enc_output, self.last_hidden_state, self.last_current_state\n",
    "      \n",
    "    def initialize_states(self, batch_size):\n",
    "      \n",
    "      self.first_hidden_state, self.first_current_state = tf.zeros([batch_size, self.lstm_size]), tf.zeros([batch_size, self.lstm_size])\n",
    "      # Returning the initializations\n",
    "      return self.first_hidden_state, self.first_current_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OFtOajkv5muj"
   },
   "source": [
    "<h3>Designing Decoder:</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1625836839975,
     "user": {
      "displayName": "Shubham Patil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiL3C1XXiVqxpUBamrWhSAqradgI0J23eGC838ulEc=s64",
      "userId": "09238778057162358648"
     },
     "user_tz": -330
    },
    "id": "8hIKmn9O5mul"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    \n",
    "    \n",
    "    def __init__(self, out_vocab_size, lstm_size, input_length):\n",
    "\n",
    "        super().__init__()\n",
    "        # Initializing the parameters\n",
    "        self.out_vocab_size = out_vocab_size\n",
    "        self.lstm_size = lstm_size\n",
    "        self.input_length = input_length\n",
    "        \n",
    "        # Initializing Embedding layer\n",
    "        self.embedding = Embedding(input_dim = self.out_vocab_size, output_dim = self.out_vocab_size, input_length = self.input_length, mask_zero = True,\n",
    "                                   name = \"embedding_layer_decoder\")\n",
    "        \n",
    "        # Intializing Decoder LSTM layer\n",
    "        self.lstm = LSTM(self.lstm_size, return_sequences = True, return_state = True, name = \"Encoder_LSTM\")\n",
    "\n",
    "    def call(self, input):\n",
    "\n",
    "        # Unpacking the input\n",
    "        input_sequence, states = input[0], input[1]\n",
    "        \n",
    "        # Passing input sequence to embedding layer\n",
    "        target_embedd = self.embedding(input_sequence)\n",
    "        \n",
    "        # Passing embedidng layer output to lstm layer\n",
    "        dec_output, last_hidden_state, last_current_state = self.lstm(target_embedd, initial_state = states)\n",
    "        \n",
    "        # Returning the outputs\n",
    "        return dec_output, last_hidden_state, last_current_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4UOuZNfm5muo"
   },
   "source": [
    "<h3>Designing Encoder Decoder Model:</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1625836839976,
     "user": {
      "displayName": "Shubham Patil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiL3C1XXiVqxpUBamrWhSAqradgI0J23eGC838ulEc=s64",
      "userId": "09238778057162358648"
     },
     "user_tz": -330
    },
    "id": "WEd9ZUuf5muq"
   },
   "outputs": [],
   "source": [
    "class Encoder_Decoder(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, inp_vocab_size, out_vocab_size, lstm_size, input_length, batch_size):\n",
    "    \n",
    "        super().__init__()\n",
    "        # Initializing the parameters\n",
    "        self.lstm_size = lstm_size\n",
    "        self.input_length = input_length\n",
    "        self.inp_vocab_size = inp_vocab_size + 1\n",
    "        self.out_vocab_size = out_vocab_size + 1\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        #Creating Encoder model object\n",
    "        self.encoder = Encoder(inp_vocab_size = self.inp_vocab_size, lstm_size = self.lstm_size, input_length = self.input_length)\n",
    "        \n",
    "        #Creating Decoder model object\n",
    "        self.decoder = Decoder(out_vocab_size = self.out_vocab_size, lstm_size = self.lstm_size, input_length = self.input_length)\n",
    "        \n",
    "        #Intializing Dense layer of length out_vocab_size with softmax activation\n",
    "        self.dense   = Dense(self.out_vocab_size, activation = 'softmax')\n",
    "    \n",
    "    def call(self, data):\n",
    "        \n",
    "        # Unpacking data\n",
    "        enc_inp, dec_inp = data[0], data[1]\n",
    "        \n",
    "        # Initializing Encoder initial states\n",
    "        initial_state = self.encoder.initialize_states(self.batch_size)\n",
    "        \n",
    "        # Calling Encoder model object\n",
    "        encoder_output, encoder_hidden, encoder_current = self.encoder([enc_inp, initial_state])\n",
    "        # Calling Decoder model object\n",
    "        decoder_output, decoder_hidden, decoder_current = self.decoder([dec_inp, [encoder_hidden, encoder_current]])\n",
    "        # Calling output dense layer\n",
    "        output = self.dense(decoder_output)\n",
    "        \n",
    "        # Returning outputs\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THGrF5PY5muq"
   },
   "source": [
    "<h2>Designing the Data Pipeline:</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uMr6HvW-5mu0"
   },
   "source": [
    "<h3>Preprocessing the Data:</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1625836840668,
     "user": {
      "displayName": "Shubham Patil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiL3C1XXiVqxpUBamrWhSAqradgI0J23eGC838ulEc=s64",
      "userId": "09238778057162358648"
     },
     "user_tz": -330
    },
    "id": "6HNiDKr05mu3"
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    \n",
    "    def __init__(self, data, tknizer_informal, tknizer_formal, max_len):\n",
    "        \n",
    "        self.encoder_inps = data['encoder_inp'].values\n",
    "        self.decoder_inps = data['decoder_inp'].values\n",
    "        self.decoder_outs = data['decoder_out'].values\n",
    "        self.tknizer_informal = tknizer_informal\n",
    "        self.tknizer_formal = tknizer_formal\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        \n",
    "        # Tokenizing the sequences by passing them in lists as required by tokenizer\n",
    "        self.encoder_inp_seq = self.tknizer_informal.texts_to_sequences([self.encoder_inps[i]])\n",
    "        self.decoder_inp_seq = self.tknizer_formal.texts_to_sequences([self.decoder_inps[i]])\n",
    "        self.decoder_out_seq = self.tknizer_formal.texts_to_sequences([self.decoder_outs[i]])\n",
    "        \n",
    "        # Padding the sequences with zeros\n",
    "        self.encoder_inp_seq = pad_sequences(self.encoder_inp_seq, maxlen = self.max_len, dtype = 'int32', padding = 'post')\n",
    "        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq, maxlen = self.max_len, dtype = 'int32', padding = 'post')\n",
    "        self.decoder_out_seq = pad_sequences(self.decoder_out_seq, maxlen = self.max_len, dtype = 'int32', padding = 'post')\n",
    "        return self.encoder_inp_seq, self.decoder_inp_seq, self.decoder_out_seq\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.encoder_inps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P274fDF45mvG"
   },
   "source": [
    "<h3>Creating Dataloader:</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1625836841598,
     "user": {
      "displayName": "Shubham Patil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiL3C1XXiVqxpUBamrWhSAqradgI0J23eGC838ulEc=s64",
      "userId": "09238778057162358648"
     },
     "user_tz": -330
    },
    "id": "ItHnQjEA5mvH"
   },
   "outputs": [],
   "source": [
    "class Dataloader(tf.keras.utils.Sequence):    \n",
    "    \n",
    "    def __init__(self, dataset, batch_size = 1):\n",
    "        \n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.indexes = np.arange(len(self.dataset.encoder_inps))\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        # Tracking indices of start and stop\n",
    "        start = i * self.batch_size\n",
    "        stop = (i + 1) * self.batch_size\n",
    "        data = []\n",
    "        for j in range(start, stop):\n",
    "            data.append(self.dataset[j])\n",
    "        \n",
    "        # Creating data in tuples of form ([[encoder_inp], [decoder_inp]], decoder_out)\n",
    "        batch = [np.squeeze(np.stack(samples, axis = 1), axis = 0) for samples in zip(*data)]\n",
    "        \n",
    "        return tuple([[batch[0],batch[1]],batch[2]])\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.indexes) // self.batch_size\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \n",
    "        self.indexes = np.random.permutation(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1625836842294,
     "user": {
      "displayName": "Shubham Patil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiL3C1XXiVqxpUBamrWhSAqradgI0J23eGC838ulEc=s64",
      "userId": "09238778057162358648"
     },
     "user_tz": -330
    },
    "id": "XGfi_PWlDVgf",
    "outputId": "dab92a77-a280-4759-cefd-916300508140"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training set: (7484, 3)\n",
      "Shape of Validation set: (197, 3)\n",
      "Shape of Test set: (192, 3)\n",
      "\n",
      "Vocab size of Informal text: 120\n",
      "Vocab size of Formal text: 92\n"
     ]
    }
   ],
   "source": [
    "# Lading pickle objects\n",
    "train = joblib.load('train.pkl')\n",
    "validation = joblib.load('validation.pkl')\n",
    "test = joblib.load('test.pkl')\n",
    "\n",
    "print(f\"Shape of Training set: {train.shape}\")\n",
    "print(f\"Shape of Validation set: {validation.shape}\")\n",
    "print(f\"Shape of Test set: {test.shape}\")\n",
    "\n",
    "tknizer_informal = joblib.load('tknizer_informal.pkl')\n",
    "tknizer_formal = joblib.load('tknizer_formal.pkl')\n",
    "\n",
    "# Printing sizes of vocabularies\n",
    "vocab_size_informal = len(tknizer_informal.word_index.keys())\n",
    "print(f\"\\nVocab size of Informal text: {vocab_size_informal}\")\n",
    "\n",
    "vocab_size_formal = len(tknizer_formal.word_index.keys())\n",
    "print(f\"Vocab size of Formal text: {vocab_size_formal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1625836844894,
     "user": {
      "displayName": "Shubham Patil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiL3C1XXiVqxpUBamrWhSAqradgI0J23eGC838ulEc=s64",
      "userId": "09238778057162358648"
     },
     "user_tz": -330
    },
    "id": "Qz61fFy8D74m",
    "outputId": "820e7073-70c2-4715-c3f8-b0854cfe6f1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 200) (64, 200) (64, 200)\n"
     ]
    }
   ],
   "source": [
    "# Defining parameters\n",
    "BATCH_SIZE = 64\n",
    "MAX_LEN = 200\n",
    "\n",
    "# Preprocessing data\n",
    "train_dataset = Dataset(train, tknizer_informal, tknizer_formal, MAX_LEN)\n",
    "validation_dataset  = Dataset(validation, tknizer_formal, tknizer_formal, MAX_LEN)\n",
    "\n",
    "# Creating Dataloader\n",
    "train_dataloader = Dataloader(train_dataset, batch_size = BATCH_SIZE)\n",
    "validation_dataloader = Dataloader(validation_dataset, batch_size = BATCH_SIZE)\n",
    "\n",
    "# Checking the dimensions \n",
    "print(train_dataloader[0][0][0].shape, train_dataloader[0][0][1].shape, train_dataloader[0][1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LrqwtrIg5mvJ"
   },
   "source": [
    "<h2>Training the Encoder Decoder Model:</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VWIjVT4s5mvK"
   },
   "source": [
    "<h3>Creating model callbacks:</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1625836847145,
     "user": {
      "displayName": "Shubham Patil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiL3C1XXiVqxpUBamrWhSAqradgI0J23eGC838ulEc=s64",
      "userId": "09238778057162358648"
     },
     "user_tz": -330
    },
    "id": "AF0Idppu5mvL"
   },
   "outputs": [],
   "source": [
    "def create_tensorboard_cb(model):\n",
    "    \n",
    "    import time\n",
    "    root_logdir = os.path.join(os.curdir, model)\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    logdir = os.path.join(root_logdir, run_id)\n",
    "    return tf.keras.callbacks.TensorBoard(logdir, histogram_freq = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wXpy48n-5mvN"
   },
   "source": [
    "<h3>Training the Encoder Decoder Model:</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54396,
     "status": "ok",
     "timestamp": 1625837049845,
     "user": {
      "displayName": "Shubham Patil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiL3C1XXiVqxpUBamrWhSAqradgI0J23eGC838ulEc=s64",
      "userId": "09238778057162358648"
     },
     "user_tz": -330
    },
    "id": "4pMHJa915mvN",
    "outputId": "150d19d3-3a78-4784-e14b-f6ee7fc2ab70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4323INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 250s 2s/step - loss: 2.4323 - val_loss: 1.8624 - lr: 0.0100\n",
      "Epoch 2/50\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6558INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 263s 2s/step - loss: 1.6558 - val_loss: 1.5061 - lr: 0.0100\n",
      "Epoch 3/50\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4122INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 243s 2s/step - loss: 1.4122 - val_loss: 1.3680 - lr: 0.0100\n",
      "Epoch 4/50\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2852INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 221s 2s/step - loss: 1.2852 - val_loss: 1.2940 - lr: 0.0100\n",
      "Epoch 5/50\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1924INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 237s 2s/step - loss: 1.1924 - val_loss: 1.2342 - lr: 0.0100\n",
      "Epoch 6/50\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1192INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 229s 2s/step - loss: 1.1192 - val_loss: 1.1845 - lr: 0.0100\n",
      "Epoch 7/50\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0553INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 225s 2s/step - loss: 1.0553 - val_loss: 1.1447 - lr: 0.0100\n",
      "Epoch 8/50\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0022INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 226s 2s/step - loss: 1.0022 - val_loss: 1.1057 - lr: 0.0100\n",
      "Epoch 9/50\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.9529INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 238s 2s/step - loss: 0.9529 - val_loss: 1.0801 - lr: 0.0100\n",
      "Epoch 10/50\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.9124INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 255s 2s/step - loss: 0.9124 - val_loss: 1.0528 - lr: 0.0100\n",
      "Epoch 11/50\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.8843\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "116/116 [==============================] - 256s 2s/step - loss: 0.8843 - val_loss: 1.0759 - lr: 0.0100\n",
      "Epoch 12/50\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.7748INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 295s 3s/step - loss: 0.7748 - val_loss: 0.9416 - lr: 0.0050\n",
      "Epoch 13/50\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.7189INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 402s 3s/step - loss: 0.7189 - val_loss: 0.9105 - lr: 0.0050\n",
      "Epoch 14/50\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6918INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 255s 2s/step - loss: 0.6918 - val_loss: 0.8953 - lr: 0.0050\n",
      "Epoch 15/50\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6633INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 272s 2s/step - loss: 0.6633 - val_loss: 0.8737 - lr: 0.0050\n",
      "Epoch 16/50\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6408INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 251s 2s/step - loss: 0.6408 - val_loss: 0.8600 - lr: 0.0050\n",
      "Epoch 17/50\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6233INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 269s 2s/step - loss: 0.6233 - val_loss: 0.8541 - lr: 0.0050\n",
      "Epoch 18/50\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6067\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "116/116 [==============================] - 231s 2s/step - loss: 0.6067 - val_loss: 0.8653 - lr: 0.0050\n",
      "Epoch 19/50\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5319INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 230s 2s/step - loss: 0.5319 - val_loss: 0.7676 - lr: 0.0025\n",
      "Epoch 20/50\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4969INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 265s 2s/step - loss: 0.4969 - val_loss: 0.7612 - lr: 0.0025\n",
      "Epoch 21/50\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4792INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 282s 2s/step - loss: 0.4792 - val_loss: 0.7500 - lr: 0.0025\n",
      "Epoch 22/50\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4660\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "116/116 [==============================] - 232s 2s/step - loss: 0.4660 - val_loss: 0.7520 - lr: 0.0025\n",
      "Epoch 23/50\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4309INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 261s 2s/step - loss: 0.4309 - val_loss: 0.7103 - lr: 0.0012\n",
      "Epoch 24/50\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4136INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 233s 2s/step - loss: 0.4136 - val_loss: 0.7006 - lr: 0.0012\n",
      "Epoch 25/50\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4047INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 251s 2s/step - loss: 0.4047 - val_loss: 0.6988 - lr: 0.0012\n",
      "Epoch 26/50\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3968INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 232s 2s/step - loss: 0.3968 - val_loss: 0.6913 - lr: 0.0012\n",
      "Epoch 27/50\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3893INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 259s 2s/step - loss: 0.3893 - val_loss: 0.6867 - lr: 0.0012\n",
      "Epoch 28/50\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3820INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 253s 2s/step - loss: 0.3820 - val_loss: 0.6844 - lr: 0.0012\n",
      "Epoch 29/50\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3742INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 255s 2s/step - loss: 0.3742 - val_loss: 0.6817 - lr: 0.0012\n",
      "Epoch 30/50\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3686INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 271s 2s/step - loss: 0.3686 - val_loss: 0.6785 - lr: 0.0012\n",
      "Epoch 31/50\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3620\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "116/116 [==============================] - 246s 2s/step - loss: 0.3620 - val_loss: 0.6818 - lr: 0.0012\n",
      "Epoch 32/50\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3413INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 257s 2s/step - loss: 0.3413 - val_loss: 0.6584 - lr: 6.2500e-04\n",
      "Epoch 33/50\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3307INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 259s 2s/step - loss: 0.3307 - val_loss: 0.6548 - lr: 6.2500e-04\n",
      "Epoch 34/50\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3258INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 247s 2s/step - loss: 0.3258 - val_loss: 0.6501 - lr: 6.2500e-04\n",
      "Epoch 35/50\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3229\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "116/116 [==============================] - 234s 2s/step - loss: 0.3229 - val_loss: 0.6529 - lr: 6.2500e-04\n",
      "Epoch 36/50\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3141INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 261s 2s/step - loss: 0.3141 - val_loss: 0.6429 - lr: 3.1250e-04\n",
      "Epoch 37/50\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3096INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 265s 2s/step - loss: 0.3096 - val_loss: 0.6421 - lr: 3.1250e-04\n",
      "Epoch 38/50\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3068\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "116/116 [==============================] - 218s 2s/step - loss: 0.3068 - val_loss: 0.6424 - lr: 3.1250e-04\n",
      "Epoch 39/50\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3029INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 242s 2s/step - loss: 0.3029 - val_loss: 0.6408 - lr: 1.5625e-04\n",
      "Epoch 40/50\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3010INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 231s 2s/step - loss: 0.3010 - val_loss: 0.6405 - lr: 1.5625e-04\n",
      "Epoch 41/50\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2996INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 217s 2s/step - loss: 0.2996 - val_loss: 0.6394 - lr: 1.5625e-04\n",
      "Epoch 42/50\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2983INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 220s 2s/step - loss: 0.2983 - val_loss: 0.6386 - lr: 1.5625e-04\n",
      "Epoch 43/50\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2970\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 220s 2s/step - loss: 0.2970 - val_loss: 0.6385 - lr: 1.5625e-04\n",
      "Epoch 44/50\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2950INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Enc_Dec/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 239s 2s/step - loss: 0.2950 - val_loss: 0.6384 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "116/116 [==============================] - 196s 2s/step - loss: 0.2939 - val_loss: 0.6386 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "116/116 [==============================] - 225s 2s/step - loss: 0.2931 - val_loss: 0.6384 - lr: 1.0000e-04\n",
      "Epoch 47/50\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2922Restoring model weights from the end of the best epoch: 44.\n",
      "116/116 [==============================] - 206s 2s/step - loss: 0.2922 - val_loss: 0.6387 - lr: 1.0000e-04\n",
      "Epoch 47: early stopping\n",
      "Model: \"encoder__decoder_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_1 (Encoder)         multiple                  927025    \n",
      "                                                                 \n",
      " decoder_1 (Decoder)         multiple                  367049    \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  23901     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1317975 (5.03 MB)\n",
      "Trainable params: 1317975 (5.03 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Defining model parameters\n",
    "UNITS = 256\n",
    "EPOCHS = 50\n",
    "TRAIN_STEPS = train.shape[0]//BATCH_SIZE\n",
    "VALID_STEPS = validation.shape[0]//BATCH_SIZE\n",
    "# Creating an object of Encoder_Decoder Model class \n",
    "model  = Encoder_Decoder(inp_vocab_size = vocab_size_informal, out_vocab_size = vocab_size_formal,\n",
    "                         lstm_size = UNITS, input_length = MAX_LEN, batch_size = BATCH_SIZE)\n",
    "# Initializing Adam Optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.01)\n",
    "# Compiling the model with 'adam' optimizer and 'sparse categorical crossentropy' loss\n",
    "model.compile(optimizer = optimizer, loss = 'sparse_categorical_crossentropy')\n",
    "# Creating callbacks to control model training\n",
    "learning_rate_cb = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_loss', factor = 0.5, verbose = 1, patience = 1, min_lr = 0.0001)\n",
    "tensorboard_cb = create_tensorboard_cb(\"Enc_Dec_logs\")\n",
    "stopper_cb = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 3, verbose = 1, restore_best_weights = True)\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"Enc_Dec\",\n",
    "                                                    save_best_only = True, save_weights_only = False)\n",
    "# Fitting the model on training data\n",
    "model.fit(train_dataloader, steps_per_epoch = TRAIN_STEPS, epochs = EPOCHS,\n",
    "              callbacks = [learning_rate_cb, tensorboard_cb, stopper_cb, checkpoint_cb],\n",
    "              validation_data = validation_dataloader, validation_steps = VALID_STEPS)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B0NdmwoWarTe"
   },
   "source": [
    "<h3>Creating Predict Function:</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "gjIcz43N5mvO"
   },
   "outputs": [],
   "source": [
    "def predict(input_sentence, model):\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Tokenizing and Padding the sentence\n",
    "    inputs = [tknizer_informal.word_index.get(i, 0) for i in input_sentence]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen = MAX_LEN, padding = 'post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    \n",
    "    # Initializing result string and hidden states\n",
    "    result = ''\n",
    "    hidden = tf.zeros([1, UNITS]), tf.zeros([1, UNITS])\n",
    "    \n",
    "    # Getting Encoder outputs\n",
    "    enc_out, state_h, state_c = model.encoder([inputs, hidden])\n",
    "    dec_hidden = [state_h, state_c]\n",
    "    dec_input = tf.expand_dims([tknizer_formal.word_index['<']], 0)\n",
    "    \n",
    "    # Running loop until max length or the prediction is '>' token\n",
    "    for t in range(MAX_LEN):\n",
    "        # Getting Decoder outputs\n",
    "        predictions, state_h, state_c = model.decoder([dec_input, dec_hidden])\n",
    "        dec_hidden = [state_h, state_c]\n",
    "        # Getting index of word with maximum probability\n",
    "        predicted_id = tf.argmax(model.layers[2](predictions)[0][0]).numpy()\n",
    "        # Getting output token\n",
    "        if tknizer_formal.index_word.get(predicted_id, '') == '>':\n",
    "            break\n",
    "        else:\n",
    "            result += tknizer_formal.index_word.get(predicted_id, '')\n",
    "            dec_input = tf.expand_dims([predicted_id], 0)\n",
    "    \n",
    "    # Postprocessing the result string to remove spaces between punctuations\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CerSXNVparTe"
   },
   "source": [
    "<h3>Calculating the BLEU Score:</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42017,
     "status": "ok",
     "timestamp": 1625833901637,
     "user": {
      "displayName": "Shubham Patil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiL3C1XXiVqxpUBamrWhSAqradgI0J23eGC838ulEc=s64",
      "userId": "09238778057162358648"
     },
     "user_tz": -330
    },
    "id": "GgpRZfa_FIaO",
    "outputId": "84f7b680-c900-445f-eeb4-ba090390d8b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Bleu score of predictions: 3.1277541302808807e-80\n"
     ]
    }
   ],
   "source": [
    "# Removing '<' and '>' tokens and postprocessing punctuations to make plain texts\n",
    "def rem(s):\n",
    "    if s.startswith('<'):\n",
    "        s = s[1:]\n",
    "    if s.endswith('>'):\n",
    "        s = s[:-1]\n",
    "    return s\n",
    "\n",
    "test['informals'] = test['encoder_inp'].apply(rem)\n",
    "test['formals'] = test['decoder_inp'].apply(rem)\n",
    "\n",
    "def predictor(s):\n",
    "    # Modifing predictor using model\n",
    "    result = predict(s, model)\n",
    "    return result\n",
    "test['predictions'] = test['informals'].apply(predictor)\n",
    "\n",
    "# Process inputs for Bleu score\n",
    "def convert_formals(s):\n",
    "    return [s.split()]\n",
    "def convert_predictions(s):\n",
    "    return s.split()\n",
    "\n",
    "test['formals'] = test['formals'].apply(convert_formals)\n",
    "test['predictions'] = test['predictions'].apply(convert_predictions)\n",
    "\n",
    "bleu_scores = [sentence_bleu(test['formals'].iloc[i], test['predictions'].iloc[i]) for i in range(len(test))]\n",
    "print(f\"Mean Bleu score of predictions: {np.mean(bleu_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "executionInfo": {
     "elapsed": 557,
     "status": "ok",
     "timestamp": 1625834026030,
     "user": {
      "displayName": "Shubham Patil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiL3C1XXiVqxpUBamrWhSAqradgI0J23eGC838ulEc=s64",
      "userId": "09238778057162358648"
     },
     "user_tz": -330
    },
    "id": "YAIfOpdgQmQu",
    "outputId": "addcf084-a029-48d9-b381-fda442241542"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (5, 5))\n",
    "ax = sns.distplot(bleu_scores, hist = False, kde = True, kde_kws = {'shade': True, 'linewidth': 2}, color = \"green\")\n",
    "plt.title(\"Distribution of Bleu Scores\", fontdict = title_font, pad = 20.0)\n",
    "plt.xlabel(\"Bleu Score\", fontdict = label_font)\n",
    "plt.ylabel(\"Count\", fontdict = label_font)\n",
    "for label in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    label.set_fontname('Arial')\n",
    "    label.set_fontsize(14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 390,
     "status": "ok",
     "timestamp": 1625833976556,
     "user": {
      "displayName": "Shubham Patil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiL3C1XXiVqxpUBamrWhSAqradgI0J23eGC838ulEc=s64",
      "userId": "09238778057162358648"
     },
     "user_tz": -330
    },
    "id": "m2UXnV7lFSXs",
    "outputId": "1a52161e-834a-4874-8fb5-d1add550c64b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informal Sentence: wat r ya sayin\n",
      "Formal Prediction: Haha. OK, I'm in exam papers?\n"
     ]
    }
   ],
   "source": [
    "print(\"Informal Sentence: wat r ya sayin\")\n",
    "print(f\"Formal Prediction: {predict('wat r ya sayin', model)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YPYisJgOCHxM"
   },
   "source": [
    "<h2>Error Analysis:</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1288,
     "status": "ok",
     "timestamp": 1625834157339,
     "user": {
      "displayName": "Shubham Patil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiL3C1XXiVqxpUBamrWhSAqradgI0J23eGC838ulEc=s64",
      "userId": "09238778057162358648"
     },
     "user_tz": -330
    },
    "id": "8pwiJRxcQ1aq",
    "outputId": "6e7a2e20-dc9e-4bea-f235-cb832de2d4b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Predictions:\n",
      "--------------------------------------------------\n",
      "Informal Input : [\"Don ' t konw. I second a message to then alls, they haven ' t reply. Ibf you gointo somewhere wwith Xinyi when naver mind.\"]\n",
      "Expected Output : Don't know. I send a message to them all, they haven't reply. If you going somewhere with Xinyi then never mind.\n",
      "Predicted Output : Don't know. I don't know whether I will go to buy this bag and leave the book same circuating my hair.\n",
      "Bleu Score of Prediction : 2.1732409599540408e-78\n",
      "\n",
      "\n",
      "Informal Input : [\"Hy. Tomorrow you want ty meet at 10am or hel after lunch tehn we dog ' to go fro the free about in ther morming?\"]\n",
      "Expected Output : Hey. Tomorrow you want to meet at 10am or meet after lunch then we don't go for the free about in the morning?\n",
      "Predicted Output : Hey girls. So what time? I don't know whether I want to meet up today. Are you from your name or waiting more next week?\n",
      "Bleu Score of Prediction : 2.097305268269639e-78\n",
      "\n",
      "\n",
      "Informal Input : [\"Yeal, probably vut not suer. hi lough out loud let yow know, but personally I wouldn ' t bother. Thin agian if ou are going to, I might as weel!\"]\n",
      "Expected Output : Yeah, probably but not sure. I laugh out loud let you know, but personally I wouldn't bother. Then again if you are going to, I might as well!\n",
      "Predicted Output : Yeah. I'm sorry for the 12 lessons. Then we go to school or wait for so long them tomorrow first. How come you are going to see any.\n",
      "Bleu Score of Prediction : 1.7347417019156114e-78\n",
      "\n",
      "\n",
      "Informal Input : ['What ares you eanting?']\n",
      "Expected Output : What are you eating?\n",
      "Predicted Output : What time are you working?\n",
      "Bleu Score of Prediction : 9.283142785759642e-155\n",
      "\n",
      "\n",
      "Informal Input : ['Want to go eating this night?']\n",
      "Expected Output : Want to go eating tonight?\n",
      "Predicted Output : Want to chat? Introduce please.\n",
      "Bleu Score of Prediction : 8.38826642100846e-155\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Worst Predictions:\n",
      "--------------------------------------------------\n",
      "Informal Input : ['Birth you finished your exercise yet? What be you all having for dinner party?']\n",
      "Expected Output : Have you finished your exercise yet? What are you all having for dinner?\n",
      "Predicted Output : Don't worry. You should go to the bus stop now. And maybe I will be late.\n",
      "Bleu Score of Prediction : 0.0\n",
      "\n",
      "\n",
      "Informal Input : Hi Elaine i'm jeff.care to intro...\n",
      "Expected Output : Hi, Elaine, I'm Jeff. Care to introduce?\n",
      "Predicted Output : I am still doing. I thought of on bey.\n",
      "Bleu Score of Prediction : 0.0\n",
      "\n",
      "\n",
      "Informal Input : ['Okie. reallu sourry.']\n",
      "Expected Output : Okie. Really sorry.\n",
      "Predicted Output : Okay. Then nevermind.\n",
      "Bleu Score of Prediction : 0.0\n",
      "\n",
      "\n",
      "Informal Input : ['Me am 25th mal. Chinese Malaysian.']\n",
      "Expected Output : I am 25 male. Chinese Malaysian.\n",
      "Predicted Output : Meet at Bugis nomenow. Hee, how much?\n",
      "Bleu Score of Prediction : 0.0\n",
      "\n",
      "\n",
      "Informal Input : ['Nopez. Nothing a also.']\n",
      "Expected Output : Nopez. Nothing at all.\n",
      "Predicted Output : Oh. Ok. Sweet dreams.\n",
      "Bleu Score of Prediction : 0.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sorting the indices by blue scores\n",
    "scores = np.array(bleu_scores)\n",
    "indices = np.argsort(scores)\n",
    "\n",
    "# Getting worst score indices\n",
    "worst = indices[:5]\n",
    "\n",
    "# Getting best score indices\n",
    "best = indices[-5:][::-1]\n",
    "\n",
    "print('Best Predictions:')\n",
    "print(\"-\"*50)\n",
    "for i in best:\n",
    "    print(f\"Informal Input : {test['informals'].iloc[i]}\")\n",
    "    print(f\"Expected Output : {' '.join(test['formals'].iloc[i][0])}\")\n",
    "    print(f\"Predicted Output : {' '.join(test['predictions'].iloc[i])}\")\n",
    "    print(f\"Bleu Score of Prediction : {scores[i]}\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "print('='*100)\n",
    "\n",
    "print('Worst Predictions:')\n",
    "print(\"-\"*50)\n",
    "for i in worst:\n",
    "    print(f\"Informal Input : {test['informals'].iloc[i]}\")\n",
    "    print(f\"Expected Output : {' '.join(test['formals'].iloc[i][0])}\")\n",
    "    print(f\"Predicted Output : {' '.join(test['predictions'].iloc[i])}\")\n",
    "    print(f\"Bleu Score of Prediction : {scores[i]}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Simple_Encoder_Decoder.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "f8165ba06ef4d1b8944ddab7bc27dc2417440af6c4fcab695d31da6788090849"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
